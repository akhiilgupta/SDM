package com.first.project

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
 
object Wordcount {
   def main(args: Array[String]) {
   System.setProperty("hadoop.home.dir", "C:\\hadoop-common-2.2.0-bin-master\\bin");
    
   val conf = new SparkConf()
   .setAppName("WordCount")
    
   val sc = new SparkContext(conf)
   
   if (args.length < 2) {
   println("Usage: ScalaWordCount <input> <output>")
   System.exit(1)
   }
   
   val rawData = sc.textFile(args(0))
    
   val words = rawData.flatMap(line => line.split(" "))
    
   val wordCount = words.map(word => (word, 1)).reduceByKey(_ + _)
    
   wordCount.saveAsTextFile(args(1))
   
   sc.stop
   }
}