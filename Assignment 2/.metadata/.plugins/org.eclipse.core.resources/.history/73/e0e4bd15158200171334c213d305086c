package mypackage

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import scala.io.Source


object Percentile {
  def main(args: Array[String]): Unit = {
    System.setProperty("hadoop.home.dir", "C:\\hadoop");
    
    val spConfig = (new SparkConf).setAppName("Spark Matrix Multiplication").setMaster("local[*]");
    val sc = new SparkContext(spConfig);
    val listOfLines = Source.fromFile("input_list.txt").getLines.toArray;
    val ls = listOfLines.map(_.toInt);
    
    val list = sc.parallelize(ls, 3).cache();
    val sortedList = list.sortBy(x => x)//.zipWithIndex().filter(x => List(.25*list.count().toInt,
        //5*list.count().toInt , list.count().toInt).contains(x._2));
    sortedList.saveAsTextFile("precentiles");
    sc.stop();
  }
}