package mypackage

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import scala.io.Source
import org.apache.spark.rdd.RDD


object Percentile {
  def main(args: Array[String]): Unit = {
    def findPercentile(data: RDD[(Int, Long)], percentile: Int): Int = {
      if(data.count() < 1){
        return -1
      }
    }
    
    val spConfig = (new SparkConf).setAppName("Spark Matrix Multiplication").setMaster("local[*]");
    val sc = new SparkContext(spConfig);
    val listOfLines = Source.fromFile("input_list.txt").getLines.toArray;
    val ls = listOfLines.map(_.toInt);
    
    val list = sc.parallelize(ls, 3).zipWithIndex().map(_.swap).collect().foreach(print);
    
    
    sc.stop();
  }
}